# Architecture Documentation

## ğŸ—ï¸ System Design

### Overview

The Medical Event Integration system is built as a **microservice architecture** with two NestJS services communicating via HTTP and sharing a MongoDB database for persistence.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Client Layer                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â”‚ POST /events
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Ingest Service (Port 3000)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ EventsControllerâ”‚â†’â”‚ EventsServiceâ”‚â†’â”‚  QueueService  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                 â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚ HTTP POST /queue
                                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Processor Service (Port 3001)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚WorkerControllerâ”‚â†’â”‚ WorkerService â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                            â”‚                                      â”‚
â”‚                            â”‚ Per-Patient Locks                    â”‚
â”‚                            â–¼                                      â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                     â”‚ Process Eventâ”‚                              â”‚
â”‚                     â”‚ (~5 seconds) â”‚                              â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â”‚ Write
                                       â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚       MongoDB           â”‚
                          â”‚  processed_events       â”‚
                          â”‚  (eventId: unique)      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Design Decisions

### 1. **Two-Service Architecture**

**Why not a single service?**

- **Separation of Concerns**: Ingest handles API validation, Processor handles business logic
- **Independent Scaling**: Can scale processor instances independently
- **Fault Isolation**: Processor crashes don't affect ingestion
- **Clear Boundaries**: Easy to understand, test, and maintain

**Why not a message queue?**

The requirements specified **HTTP communication** for simplicity. In production, a message queue (RabbitMQ, Kafka) would be preferred for:
- Better fault tolerance
- Automatic retry mechanisms
- Message persistence
- Backpressure handling

### 2. **HTTP as Transport**

**Advantages:**
- âœ… Simple to implement and test
- âœ… No additional infrastructure (no broker)
- âœ… Standard REST patterns
- âœ… Easy debugging with curl/Postman

**Limitations:**
- âŒ No built-in retry mechanism
- âŒ No message persistence if processor is down
- âŒ Synchronous coupling (mitigated with fire-and-forget)

**Mitigation:**
- Processor accepts events immediately (202 Accepted)
- Processes asynchronously in background
- Can add retry logic in QueueService if needed

### 3. **Idempotency Strategy**

**Implementation:**
```typescript
// Unique index on eventId
@Prop({ required: true, unique: true })
eventId!: string;
```

**How it works:**
1. Generate UUID for each event
2. MongoDB unique constraint prevents duplicates
3. Check before processing to skip early
4. Handle duplicate key errors gracefully

**Edge cases handled:**
- Concurrent duplicate requests â†’ MongoDB rejects at insert
- Retry scenarios â†’ Early detection in service layer
- Race conditions â†’ Unique index guarantees atomicity

### 4. **Per-Patient Ordering**

**Problem:** Events for the same patient must process sequentially, but different patients can process in parallel.

**Solution: In-Memory Lock Map**
```typescript
private readonly patientLocks = new Map<string, Promise<void>>();

async processEvent(event: QueueEventDto): Promise<void> {
  const processingPromise = this.processWithLock(event);
  this.patientLocks.set(event.patientId, processingPromise);
  
  try {
    await processingPromise;
  } finally {
    this.patientLocks.delete(event.patientId);
  }
}
```

**How it works:**
1. Event arrives for `patient-123`
2. Check if `patientLocks.has('patient-123')`
3. If yes, await previous promise
4. Process current event
5. Store promise in map
6. Clean up after completion

**Characteristics:**
- âœ… Same patient â†’ sequential (one at a time)
- âœ… Different patients â†’ parallel (no blocking)
- âœ… Memory-efficient (locks removed after processing)
- âš ï¸ Single-instance only (won't work across replicas)

**Production Alternative:**
For multi-instance deployments, use:
- **Redis distributed locks** (Redlock algorithm)
- **Message queue partitioning** (Kafka partitions by patientId)
- **Database advisory locks** (PostgreSQL)

### 5. **Processing Simulation**

```typescript
private async simulateProcessing(): Promise<void> {
  const delay = 5000 + Math.random() * 1000; // 5-6 seconds
  return new Promise((resolve) => setTimeout(resolve, delay));
}
```

- Simulates real medical data processing
- Random jitter (5-6s) mimics real-world variance
- Demonstrates async handling under load

---

## ğŸ“Š Data Model

### MongoDB Collection: `processed_events`

```typescript
{
  eventId: string;           // UUID, unique index
  patientId: string;         // Indexed for queries
  type: string;              // Event type
  data: object;              // Arbitrary event data
  ts: string;                // ISO8601 timestamp
  processedAt: Date;         // Processing completion time
  processingDurationMs: number; // Performance metric
  result: {
    status: string;
    message: string;
    error?: string;
  };
  createdAt: Date;           // Auto-generated
  updatedAt: Date;           // Auto-generated
}
```

**Indexes:**
1. `eventId` (unique) - Idempotency enforcement
2. `patientId` - Fast patient queries
3. `{patientId, ts}` (compound) - Ordered patient events

---

## ğŸš€ Scalability Considerations

### Current Limitations

| Component | Single Instance | Multiple Instances |
|-----------|----------------|-------------------|
| Ingest Service | âœ… Stateless | âœ… Can scale horizontally |
| Processor Service | âœ… Works | âš ï¸ Needs distributed locks |
| MongoDB | âœ… Works | âš ï¸ Needs replica set |

### Scaling to Multiple Instances

#### Ingest Service
```yaml
ingest-service:
  deploy:
    replicas: 3
```
âœ… **No changes needed** - completely stateless

#### Processor Service
```yaml
processor-service:
  deploy:
    replicas: 3
```
âš ï¸ **Requires changes:**

**Option 1: Distributed Locks (Redis)**
```typescript
import Redlock from 'redlock';

async processWithLock(event: QueueEventDto) {
  const lock = await redlock.acquire([`patient:${event.patientId}`], 10000);
  try {
    await this.processEventInternal(event);
  } finally {
    await lock.release();
  }
}
```

**Option 2: Message Queue Partitioning (Kafka)**
```typescript
// Produce to partition based on patientId
const partition = hash(event.patientId) % numPartitions;
await producer.send({
  topic: 'events',
  partition,
  messages: [{ value: JSON.stringify(event) }],
});
```

**Option 3: Sticky Assignment**
```typescript
// Route patient to specific instance
const instanceId = hash(patientId) % numInstances;
// Use load balancer with consistent hashing
```

#### MongoDB
```yaml
# Replica Set for high availability
mongodb:
  image: mongo:7
  command: ["--replSet", "rs0"]
```

---

## ğŸ›¡ï¸ Fault Tolerance

### Current Handling

| Failure Scenario | Behavior | Recovery |
|-----------------|----------|----------|
| Processor crash during processing | Event lost | Manual retry |
| MongoDB connection lost | Service crashes | Docker restart |
| Duplicate event sent | Skipped silently | âœ… Handled |
| Invalid payload | 400 error returned | âœ… Handled |

### Production Enhancements

#### 1. **Dead Letter Queue**
```typescript
async processEvent(event: QueueEventDto) {
  try {
    await this.processEventInternal(event);
  } catch (error) {
    await this.deadLetterQueue.publish(event, error);
    throw error;
  }
}
```

#### 2. **Retry Logic**
```typescript
async publishWithRetry(event: IngestEventDto, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await this.httpService.post(url, event);
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await sleep(2 ** i * 1000); // Exponential backoff
    }
  }
}
```

#### 3. **Circuit Breaker**
```typescript
import CircuitBreaker from 'opossum';

const breaker = new CircuitBreaker(this.publish, {
  timeout: 3000,
  errorThresholdPercentage: 50,
  resetTimeout: 30000,
});
```

---

## ğŸ“ˆ Performance Characteristics

### Throughput

**Target:** 1000 events/min = ~16.7 events/sec

**Theoretical Max:**
- Single processor instance: 1 event per 5s = **0.2 events/sec per patient**
- With 100 different patients: **20 events/sec** âœ…

**Bottleneck:** Processing time (5 seconds)

**Scaling:**
- Horizontal: Add processor instances
- Vertical: Optimize processing logic
- Queue: Add message broker for buffering

### Latency

| Operation | Duration |
|-----------|----------|
| Ingest API â†’ Response | < 100ms |
| Queue â†’ Processor | < 50ms |
| Processing | 5-6 seconds |
| MongoDB Write | < 50ms |
| **Total (ingestion)** | **< 150ms** |
| **Total (end-to-end)** | **~5.2 seconds** |

### Resource Usage

**Per Instance:**
- CPU: ~0.5 cores (idle), ~1 core (under load)
- Memory: ~150MB (Node.js + NestJS)
- Network: ~1KB per event

---

## ğŸ”’ Security Considerations

### Current Implementation

âš ï¸ **Development Only** - Not production-ready

Missing:
- âŒ Authentication/Authorization
- âŒ API rate limiting
- âŒ Input sanitization (beyond validation)
- âŒ HTTPS/TLS
- âŒ Secret management

### Production Checklist

1. **Authentication**
   ```typescript
   @UseGuards(JwtAuthGuard)
   @Post('events')
   async ingest(@Body() event: IngestEventDto) { }
   ```

2. **Rate Limiting**
   ```typescript
   @Throttle(1000, 60) // 1000 req/min
   async ingest() { }
   ```

3. **Input Sanitization**
   ```typescript
   import mongoSanitize from 'express-mongo-sanitize';
   app.use(mongoSanitize());
   ```

4. **HTTPS**
   ```typescript
   const httpsOptions = {
     key: fs.readFileSync('./secrets/private-key.pem'),
     cert: fs.readFileSync('./secrets/certificate.pem'),
   };
   await NestFactory.create(AppModule, { httpsOptions });
   ```

---

## ğŸ§ª Testing Strategy

### Unit Tests
```typescript
describe('WorkerService', () => {
  it('should enforce per-patient ordering', async () => {
    const service = new WorkerService(mockModel);
    const events = [event1, event2, event3];
    
    // All for same patient
    await Promise.all(events.map(e => service.processEvent(e)));
    
    // Assert sequential processing
    expect(processingOrder).toEqual([event1, event2, event3]);
  });
});
```

### Integration Tests
```bash
# Start test environment
docker-compose -f docker-compose.test.yml up

# Run tests
npm run test:e2e
```

### Load Tests
```bash
# Apache Bench
ab -n 10000 -c 100 http://localhost:3000/events

# k6
k6 run load-test.js
```

---

## ğŸ“ Future Improvements

1. **Message Queue Integration** (RabbitMQ/Kafka)
2. **Distributed Tracing** (OpenTelemetry)
3. **Metrics & Monitoring** (Prometheus/Grafana)
4. **API Gateway** (Kong/Nginx)
5. **Service Mesh** (Istio for larger deployments)
6. **Event Sourcing** (Full audit trail)
7. **CQRS** (Read/Write separation)
8. **GraphQL API** (Flexible querying)
9. **WebSockets** (Real-time updates)
10. **Multi-Region** (Global distribution)

---

## ğŸ¯ Summary

This architecture demonstrates:
- âœ… Microservice communication patterns
- âœ… Idempotency in distributed systems
- âœ… Per-entity ordering constraints
- âœ… Scalable design principles
- âœ… Practical trade-offs (HTTP vs Queue)

**Best for:** Demo, POC, small-scale deployments

**Not suitable for:** Mission-critical production without enhancements listed above.

