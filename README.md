# Medical Event Integration - Microservices Demo

A **NestJS + MongoDB** microservice architecture for ingesting and processing high-throughput medical events with scalability, fault tolerance, and correctness guarantees.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         HTTP          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚ â”€â”€â”€POST /eventsâ”€â”€â”€â”€â”€â”€â–¶â”‚  Ingest Service  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚   (Port 3000)    â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â”‚ HTTP POST
                                              â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚ Processor Serviceâ”‚
                                      â”‚   (Port 3001)    â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                      â”‚    MongoDB       â”‚
                                      â”‚   (Port 27017)   â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Services

1. **Ingest Service** (Port 3000)
   - Receives events via `POST /events`
   - Validates incoming payloads
   - Forwards to Processor Service via HTTP
   - Health check: `GET /health`

2. **Processor Service** (Port 3001)
   - Receives events from Ingest Service
   - Simulates ~5 seconds processing
   - Persists to MongoDB with idempotency
   - Enforces per-patient ordering
   - Health check: `GET /health`

3. **MongoDB** (Port 27017)
   - Stores processed events
   - Unique indexes ensure idempotency

## âœ¨ Features

### âœ… Requirements Met

- **High Throughput**: Handles up to 1000 events/min
- **Idempotency**: Duplicate events are safely ignored (unique `eventId` constraint)
- **Per-Patient Ordering**: Events for the same patient processed sequentially
- **Fault Tolerance**: Services restart on failure, MongoDB persists data
- **Scalability**: Horizontal scaling ready (stateless services)
- **Health Checks**: All services expose `/health` endpoints

### ğŸ”§ Implementation Details

#### Idempotency
- Unique index on `eventId` in MongoDB
- Duplicate detection before processing
- Safe handling of concurrent duplicate requests

#### Per-Patient Ordering
- In-memory lock per `patientId` in Processor Service
- Ensures sequential processing for same patient
- Different patients processed in parallel

#### Processing Simulation
- Random delay: 5-6 seconds per event
- Mimics real medical data processing

## ğŸ“¦ Installation & Setup

### Prerequisites
- Docker & Docker Compose
- Node.js 20+ (for local development)

### Quick Start with Docker

```bash
# Clone the repository
git clone <repo-url>
cd medical-integration

# Start all services
docker-compose up --build

# Services will be available at:
# - Ingest Service: http://localhost:3000
# - Processor Service: http://localhost:3001
# - MongoDB: mongodb://localhost:27017
```

### Local Development

#### Ingest Service
```bash
cd services/ingest-service/app
npm install
npm run start:dev
```

#### Processor Service
```bash
cd services/processor-service/app
npm install
npm run start:dev
```

#### Environment Variables

Create `.env` files in each service's `app` directory:

**Ingest Service (.env)**
```env
PORT=3000
MONGO_URI=mongodb://localhost:27017/medical_events
PROCESSOR_URL=http://localhost:3001
```

**Processor Service (.env)**
```env
PORT=3001
MONGO_URI=mongodb://localhost:27017/medical_events
```

## ğŸš€ API Usage

### Ingest Event

**Endpoint:** `POST http://localhost:3000/events`

**Request Body:**
```json
{
  "patientId": "patient-123",
  "type": "vitals",
  "data": {
    "heartRate": 72,
    "bloodPressure": "120/80"
  },
  "ts": "2025-10-01T10:30:00Z"
}
```

**Response (202 Accepted):**
```json
{
  "status": "queued"
}
```

### Health Checks

```bash
# Ingest Service
curl http://localhost:3000/health
# Response: {"status":"ok","service":"ingest-service"}

# Processor Service
curl http://localhost:3001/health
# Response: {"status":"ok","service":"processor-service"}
```

## ğŸ§ª Testing

### Test Idempotency

Send the same event multiple times:

```bash
# First request
curl -X POST http://localhost:3000/events \
  -H "Content-Type: application/json" \
  -d '{
    "patientId": "patient-123",
    "type": "vitals",
    "data": {"heartRate": 72},
    "ts": "2025-10-01T10:30:00Z"
  }'

# Duplicate request (will be skipped)
curl -X POST http://localhost:3000/events \
  -H "Content-Type: application/json" \
  -d '{
    "patientId": "patient-123",
    "type": "vitals",
    "data": {"heartRate": 72},
    "ts": "2025-10-01T10:30:00Z"
  }'
```

### Test Per-Patient Ordering

Send multiple events for the same patient:

```bash
# Event 1 (will process first)
curl -X POST http://localhost:3000/events \
  -H "Content-Type: application/json" \
  -d '{
    "patientId": "patient-456",
    "type": "vitals",
    "data": {"sequence": 1},
    "ts": "2025-10-01T10:00:00Z"
  }'

# Event 2 (will wait for Event 1 to complete)
curl -X POST http://localhost:3000/events \
  -H "Content-Type: application/json" \
  -d '{
    "patientId": "patient-456",
    "type": "vitals",
    "data": {"sequence": 2},
    "ts": "2025-10-01T10:05:00Z"
  }'
```

### Load Testing

Test with 1000 events/min:

```bash
# Using Apache Bench
ab -n 1000 -c 10 -T 'application/json' \
  -p event.json \
  http://localhost:3000/events
```

## ğŸ“Š MongoDB Collections

### `processed_events`
Stores successfully processed events:

```javascript
{
  "_id": ObjectId("..."),
  "eventId": "uuid-v4",
  "patientId": "patient-123",
  "type": "vitals",
  "data": { /* event data */ },
  "ts": "2025-10-01T10:30:00Z",
  "processedAt": ISODate("2025-10-01T10:30:05Z"),
  "processingDurationMs": 5234,
  "result": {
    "status": "success",
    "message": "Event processed successfully"
  },
  "createdAt": ISODate("..."),
  "updatedAt": ISODate("...")
}
```

**Indexes:**
- `eventId`: unique
- `patientId`: index
- `patientId + ts`: compound index (for ordering queries)

## ğŸ› ï¸ Project Structure

```
medical-integration/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ ingest-service/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ events/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ dto/
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ingest-event.dto.ts
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ queued-event.schema.ts
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ events.controller.ts
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ events.service.ts
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ queue.service.ts
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ events.module.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ health/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ health.controller.ts
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ health.module.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ app.module.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ main.ts
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ processor-service/
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ src/
â”‚       â”‚   â”‚   â”œâ”€â”€ worker/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ dto/
â”‚       â”‚   â”‚   â”‚   â”‚   â””â”€â”€ queue-event.dto.ts
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚       â”‚   â”‚   â”‚   â”‚   â””â”€â”€ processed-event.schema.ts
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ worker.controller.ts
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ worker.service.ts
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ worker.module.ts
â”‚       â”‚   â”‚   â”œâ”€â”€ health/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ health.controller.ts
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ health.module.ts
â”‚       â”‚   â”‚   â”œâ”€â”€ app.module.ts
â”‚       â”‚   â”‚   â””â”€â”€ main.ts
â”‚       â”‚   â””â”€â”€ package.json
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ” Monitoring & Debugging

### View Logs

```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f ingest-service
docker-compose logs -f processor-service
```

### MongoDB Shell

```bash
# Connect to MongoDB
docker exec -it medical-mongodb mongosh

# Switch to database
use medical_events

# Query processed events
db.processed_events.find().pretty()

# Check for duplicates
db.processed_events.aggregate([
  { $group: { _id: "$eventId", count: { $sum: 1 } } },
  { $match: { count: { $gt: 1 } } }
])

# Events by patient
db.processed_events.find({ patientId: "patient-123" }).sort({ ts: 1 })
```

## ğŸš¢ Scaling Considerations

### Horizontal Scaling

Both services are stateless and can be scaled horizontally:

```yaml
# docker-compose.yml
processor-service:
  deploy:
    replicas: 3  # Run 3 instances
```

**Note:** Current per-patient locking is in-memory. For true distributed scaling, use:
- Redis-based distributed locks (e.g., Redlock)
- Message queue with consumer groups (RabbitMQ, Kafka)

### Message Queue Alternative

For production, replace HTTP with a message queue:
- **RabbitMQ**: Worker queues with prefetch=1 per patient
- **Kafka**: Partition by `patientId` for ordering
- **Redis Streams**: Consumer groups with per-patient sharding

## ğŸ“ License

ISC

